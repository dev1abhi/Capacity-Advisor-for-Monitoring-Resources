# -*- coding: utf-8 -*-
"""final_model.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1bXAkRLeBQl4EeTRELLqXqszAB9y8YWqY
"""

!pip install pandas numpy requests joblib scikit-learn lightgbm prophet apscheduler matplotlib scipy

import pandas as pd
import numpy as np
from datetime import datetime, timedelta
import warnings
import requests
import joblib
from sklearn.model_selection import TimeSeriesSplit
from sklearn.metrics import (classification_report, roc_auc_score,
                            precision_recall_curve, average_precision_score)
from lightgbm import LGBMClassifier
from prophet import Prophet
from apscheduler.schedulers.background import BackgroundScheduler
import time
import os
import matplotlib.pyplot as plt
from scipy.stats import zscore

warnings.filterwarnings("ignore")

"""Configuration

"""

PROMETHEUS_URL = "http://100.27.223.212:9090"
CRASH_THRESHOLD = 0.1  # Minimum messages_in rate for crash state (relative to normal)
MODEL_RETRAIN_INTERVAL = 86400  # Retrain daily (seconds)
FORECAST_HORIZON = 12  # Forecast 12 steps ahead (5s intervals = 1 minute)
MIN_TRAIN_SAMPLES = 500  # Minimum samples needed for training
ALERT_INTERVAL = 60  # Send status alerts every 60 seconds

# Severity Levels (probability thresholds)
SEVERITY_LEVELS = {
    'critical': 0.9,
    'high': 0.7,
    'medium': 0.5,
    'low': 0.3
}

# File Paths
HISTORICAL_DATA = 'metrics_data_combined.csv'
LABELED_DATA = 'labeled_kafka_metrics.csv'
MODEL_FILE = 'kafka_crash_classifier.pkl'
FORECASTER_FILE = 'kafka_forecasters.pkl'

KAFKA_METRICS = {
    "messages_in": 'kafka_brokertopicmetrics_messagesin_total{instance="localhost:7071"}',
    "bytes_in": 'kafka_brokertopicmetrics_bytesin_total{instance="localhost:7071"}',
    "bytes_out": 'kafka_brokertopicmetrics_bytesout_total{instance="localhost:7071"}'
}

NODE_METRICS = {
    "cpu_usage": '100 - (avg by (instance)(rate(node_cpu_seconds_total{mode="idle"}[1m])) * 100)',
    "memory_usage": '(1 - (node_memory_MemAvailable_bytes / node_memory_MemTotal_bytes)) * 100',
    "disk_usage": '(1 - (node_filesystem_free_bytes{mountpoint="/"} / node_filesystem_size_bytes{mountpoint="/"})) * 100'
}

# Normal operating ranges (based on your data)
NORMAL_RANGES = {
    'messages_in': (70000, 75000),
    'cpu_usage': (3.0, 10.0),
    'memory_usage': (90.0, 92.0),
    'disk_usage': (15.0, 16.0)
}

"""Label the data"""

def label_data(df):
    """Enhanced labeling of crash events"""
    df['timestamp'] = pd.to_datetime(df['timestamp'], dayfirst=True)
    df = df.sort_values('timestamp').reset_index(drop=True)
    df = df.ffill()  # Forward fill for metrics
    df = df.dropna(subset=['messages_in', 'cpu_usage', 'memory_usage'])
    # Calculate normalized message rate (0-1 scale)
    normal_msg_min, normal_msg_max = NORMAL_RANGES['messages_in']
    df['normalized_msg_rate'] = (df['messages_in'] - normal_msg_min) / (normal_msg_max - normal_msg_min)

    # Label crashes where normalized message rate drops below threshold
    df['crash'] = (df['normalized_msg_rate'] < CRASH_THRESHOLD).astype(int)



    # Calculate moving averages and trends
    for w in [3, 6, 12]:  # 15s, 30s, 1min windows
        df[f'msg_trend_{w}'] = df['messages_in'].rolling(w).mean().pct_change()

    # Label pre-crash periods (5 minutes before actual crash)
    crash_indices = df[df['crash'] == 1].index
    for idx in crash_indices:
        pre_crash_start = max(0, idx - 60)  # 5 minutes before at 5s intervals
        df.loc[pre_crash_start:idx, 'crash'] = 1

    # Additional labeling based on system stress
    stress_conditions = (
        (df['cpu_usage'] > 80) |
        (df['memory_usage'] > 95) |
        (df['disk_usage'] > 90)
    )

    # If system is stressed AND message rate is declining, label as pre-crash
    declining_msg = df['msg_trend_12'] < -0.1  # 10% decline over 1min
    df.loc[stress_conditions & declining_msg, 'crash'] = 1

    return df

# Load and label your data (run this once)
try:
    df = pd.read_csv(HISTORICAL_DATA)
    labeled_df = label_data(df)

    # Visualize the labeling
    plt.figure(figsize=(15, 8))
    plt.plot(labeled_df['timestamp'], labeled_df['messages_in'], label='Message Rate')
    plt.scatter(labeled_df[labeled_df['crash']==1]['timestamp'],
                labeled_df[labeled_df['crash']==1]['messages_in'],
                color='red', label='Crash/Pre-crash')
    plt.title('Message Rate with Crash Labels')
    plt.xlabel('Timestamp')
    plt.ylabel('Messages/s')
    plt.legend()
    plt.xticks(rotation=45)
    plt.tight_layout()
    plt.show()

    labeled_df.to_csv(LABELED_DATA, index=False)
    print(f"Data labeled and saved to {LABELED_DATA}")
    print(f"Crash events detected: {labeled_df['crash'].sum()}")
except Exception as e:
    print(f"Error labeling data: {e}")

"""Feature Engineering"""

def create_features(df, forecast_data=None):
    """Generate comprehensive features with better error handling"""
    if df.empty:
        return pd.DataFrame()  # Return empty instead of raising error

    features = df.copy()

    # 1. Better timestamp handling
    if 'timestamp' in features.columns:
        try:
            features['timestamp'] = pd.to_datetime(features['timestamp'], errors='coerce')
            features = features.dropna(subset=['timestamp'])  # Drop rows with invalid timestamps

            # Time features
            features['hour'] = features['timestamp'].dt.hour
            features['minute'] = features['timestamp'].dt.minute
            features['time_sin'] = np.sin(2 * np.pi * features['timestamp'].dt.hour / 24)
            features['time_cos'] = np.cos(2 * np.pi * features['timestamp'].dt.hour / 24)
            features = features.drop(columns=['timestamp'])
        except:
            pass

    # 2. Safer rolling feature calculation
    windows = [3, 6, 12]
    metrics = ['messages_in', 'cpu_usage', 'memory_usage', 'disk_usage']

    for metric in metrics:
        if metric in features.columns:
            try:
                features[metric] = pd.to_numeric(features[metric], errors='coerce')
                features[metric] = features[metric].ffill().bfill()  # Handle NaNs

                for w in windows:
                    # Safer rolling calculations
                    try:
                        rolling = features[metric].rolling(window=w, min_periods=1)
                        features[f'{metric}_rolling_mean_{w}'] = rolling.mean()
                        features[f'{metric}_rolling_std_{w}'] = rolling.std()
                        features[f'{metric}_rolling_min_{w}'] = rolling.min()
                        features[f'{metric}_rolling_max_{w}'] = rolling.max()

                        if w > 1:
                            features[f'{metric}_trend_{w}'] = features[metric].diff(w)/w
                    except:
                        continue
            except:
                continue

    # Final cleanup
    features = features.select_dtypes(include=[np.number])
    features = features.ffill().bfill().dropna()

    return features

"""Train Classifier"""

import lightgbm as lgb  # Add this at the top with other imports

class KafkaCrashClassifier:
    def __init__(self):
        self.model = None
        self.feature_importances = None
        self.load_model()
    def train_model(self):
        """Train or retrain the classifier with enhanced features"""
        try:
            # 1. Data Loading and Validation
            print("\n=== Data Loading Phase ===")
            df = pd.read_csv(LABELED_DATA)
            print(f"Initial data: {len(df)} rows")
            print("Columns:", df.columns.tolist())
            print("'crash' value counts:\n", df['crash'].value_counts())

            # Handle nulls
            df = df.dropna(subset=['messages_in', 'cpu_usage', 'memory_usage', 'crash'])
            print(f"\nAfter null drop: {len(df)} rows")

            if len(df) < MIN_TRAIN_SAMPLES:
                raise ValueError(f"Only {len(df)} samples after null handling (need {MIN_TRAIN_SAMPLES})")

            # 2. Feature Engineering
            print("\n=== Feature Engineering Phase ===")
            X = create_features(df)
            print(f"Feature matrix shape: {X.shape}")

            # 3. Target Variable Handling
            y = df.loc[X.index, 'crash'].astype(int)
            print("\nTarget variable stats:")
            print("Length:", len(y))
            print("Value counts:\n", y.value_counts())
            print("NaN values:", y.isna().sum())

            # 4. Data Sanity Checks
            if len(X) != len(y):
                raise ValueError(f"Mismatched lengths: X has {len(X)} rows, y has {len(y)}")
            if y.nunique() < 2:
                raise ValueError("Target must contain both classes (0 and 1)")

            # 5. Model Training with Stratified Time Series Split
            print("\n=== Model Training Phase ===")
            n_splits = 3
            fold_size = len(X) // n_splits
            metrics = {
                'auc': [], 'balanced_accuracy': [], 'precision': [], 'recall': [], 'f1': [], 'ap': []
            }

            for fold in range(n_splits):
                # Create expanding window folds
                train_end = (fold + 1) * fold_size
                test_start = train_end
                test_end = min(train_end + fold_size, len(X))

                X_train = X.iloc[:train_end]
                y_train = y.iloc[:train_end]
                X_test = X.iloc[test_start:test_end]
                y_test = y.iloc[test_start:test_end]

                print(f"\nFold {fold+1}:")
                print(f"Train range: 0-{train_end}")
                print(f"Test range: {test_start}-{test_end}")
                print("Train class distribution:", y_train.value_counts())
                print("Test class distribution:", y_test.value_counts())

                # Ensure training set has both classes
                if y_train.nunique() < 2:
                    missing_class = 1 if 1 not in y_train.values else 0
                    nearest_sample = y[y == missing_class].index[0]
                    X_train = pd.concat([X_train, X.loc[[nearest_sample]]])
                    y_train = pd.concat([y_train, y.loc[[nearest_sample]]])
                    print("Added missing class to training set")

                # Prepare callbacks only if test set has both classes
                callbacks = []
                if y_test.nunique() > 1:
                    callbacks.extend([
                        lgb.early_stopping(stopping_rounds=20, verbose=False),
                        lgb.log_evaluation(period=0)
                    ])
                else:
                    print("Test set has only one class - skipping evaluation callbacks")

                tscv = TimeSeriesSplit(n_splits=3)
                model = LGBMClassifier(
                    objective='binary',
                    n_estimators=200,
                    learning_rate=0.05,
                    scale_pos_weight=(1 - y_train.mean()) / y_train.mean(),
                    random_state=42,
                    verbose=-1,
                    class_weight='balanced',
                    is_unbalanced=True
                )

                # Fit with appropriate parameters
                fit_params = {
                    'X': X_train,
                    'y': y_train,
                    'eval_set': [(X_test, y_test)] if y_test.nunique() > 1 else None,
                    'eval_metric': 'auc' if y_test.nunique() > 1 else None,
                    'callbacks': callbacks if callbacks else None
                }

                # Remove None parameters
                fit_params = {k: v for k, v in fit_params.items() if v is not None}

                model.fit(**fit_params)

                # Evaluation (only if test set has both classes)
                if y_test.nunique() > 1:
                    y_pred = model.predict_proba(X_test)[:, 1]

                    # Calculate metrics safely
                    try:
                        metrics['auc'].append(roc_auc_score(y_test, y_pred))
                        metrics['ap'].append(average_precision_score(y_test, y_pred))
                    except Exception as e:
                        print(f"Error calculating AUC/AP: {e}")
                        metrics['auc'].append(np.nan)
                        metrics['ap'].append(np.nan)

                    y_pred_class = (y_pred > 0.5).astype(int)

                    # Safely generate classification report
                    try:
                        report = classification_report(
                            y_test,
                            y_pred_class,
                            output_dict=True,
                            zero_division=0
                        )

                        # Get metrics for both classes safely
                        class_metrics = {
                            '0': report.get('0', {'precision': 0, 'recall': 0, 'f1-score': 0}),
                            '1': report.get('1', {'precision': 0, 'recall': 0, 'f1-score': 0})
                        }

                        # Store metrics for positive class (1)
                        for metric in ['precision', 'recall', 'f1']:
                            metrics[metric].append(class_metrics['1'][metric])
                    except Exception as e:
                        print(f"Error generating classification report: {e}")
                        for metric in ['precision', 'recall', 'f1']:
                            metrics[metric].append(np.nan)
                else:
                    print("Skipping evaluation - test set has only one class")
                    for metric in ['auc', 'ap', 'precision', 'recall', 'f1']:
                        metrics[metric].append(np.nan)

                print(f"Fold {fold+1} completed")

            # 6. Final Model Training
            print("\n=== Final Model Training ===")
            self.model = LGBMClassifier(
                objective='binary',
                n_estimators=200,
                learning_rate=0.05,
                scale_pos_weight=(1 - y.mean()) / y.mean(),
                random_state=42,
                verbose=-1
            ).fit(X, y)

            # Save model and feature importances
            joblib.dump(self.model, MODEL_FILE)
            self.feature_importances = pd.DataFrame({
                'feature': X.columns,
                'importance': self.model.feature_importances_
            }).sort_values('importance', ascending=False)

            # 7. Results
            print("\n=== Training Results ===")
            print("Average metrics (excluding invalid folds):")
            for metric, values in metrics.items():
                valid_values = [v for v in values if not np.isnan(v)]
                if valid_values:
                    print(f"{metric}: {np.mean(valid_values):.3f} (from {len(valid_values)} folds)")
                else:
                    print(f"{metric}: No valid folds for evaluation")

            return True

        except Exception as e:
            print("\n=== CRITICAL ERROR ===")
            print("Error details:", str(e))

            # Save problematic data for debugging
            if 'X' in locals() and 'y' in locals():
                pd.concat([X, y], axis=1).to_csv('debug_training_data.csv')
                print("Debug data saved to 'debug_training_data.csv'")

            raise ValueError(f"Training failed: {str(e)}") from e
    def load_model(self):
        """Load saved model or train new one"""
        try:
            if os.path.exists(MODEL_FILE):
                self.model = joblib.load(MODEL_FILE)
                print("Loaded existing crash prediction model")

                # Try to load feature importances if available
                try:
                    feature_imp = pd.DataFrame({
                        'feature': self.model.feature_name_,
                        'importance': self.model.feature_importances_
                    })
                    self.feature_importances = feature_imp.sort_values('importance', ascending=False)
                except:
                    pass
            else:
                print("No saved model found - training new one")
                self.train_model()
        except Exception as e:
            print(f"Error loading model: {e}")
            self.train_model()

"""Forecast With Prophet"""

class MetricForecaster:
    def __init__(self):
        self.models = {}
        self.load_models()

    def train_forecasters(self, df):
        """Train Prophet models for each metric with enhanced config"""
        df = df.copy()
        df['timestamp'] = pd.to_datetime(df['timestamp'], dayfirst=True)

        for metric in ['messages_in', 'cpu_usage', 'memory_usage', 'disk_usage']:
            try:
                print(f"Training Prophet model for {metric}...")
                data = df[['timestamp', metric]].dropna()
                data.columns = ['ds', 'y']

                # Configure model based on metric characteristics
                if metric == 'messages_in':
                    # Messages have stronger seasonality
                    model = Prophet(
                        daily_seasonality=True,
                        weekly_seasonality=False,
                        yearly_seasonality=False,
                        changepoint_prior_scale=0.05,
                        seasonality_mode='multiplicative'
                    )
                else:
                    # Resource usage metrics
                    model = Prophet(
                        daily_seasonality=False,
                        changepoint_prior_scale=0.1,
                        seasonality_mode='additive'
                    )

                model.fit(data)
                self.models[metric] = model

                # Plot components for diagnosis
                future = model.make_future_dataframe(periods=0)
                fig = model.plot_components(model.predict(future))
                plt.title(f'{metric} Forecast Components')
                plt.show()

            except Exception as e:
                print(f"Error training Prophet for {metric}: {e}")
                raise

        # Save trained models
        joblib.dump(self.models, FORECASTER_FILE)

    def forecast(self):
        """Generate forecasts for all metrics with uncertainty"""
        if not self.models:
            print("No forecast models available")
            return None

        forecasts = {}
        future = self.models['messages_in'].make_future_dataframe(
            periods=FORECAST_HORIZON,
            freq='5s',
            include_history=False
        )

        for metric, model in self.models.items():
            try:
                forecast = model.predict(future)

                # Get point forecast and uncertainty
                forecasts[f'{metric}_forecast'] = forecast['yhat'].values
                forecasts[f'{metric}_upper'] = forecast['yhat_upper'].values
                forecasts[f'{metric}_lower'] = forecast['yhat_lower'].values

                # Calculate trend (slope over forecast horizon)
                x = np.arange(len(forecast['yhat']))
                slope = np.polyfit(x, forecast['yhat'], 1)[0]
                forecasts[f'{metric}_trend'] = slope

            except Exception as e:
                print(f"Error forecasting {metric}: {e}")
                forecasts[f'{metric}_forecast'] = None
                forecasts[f'{metric}_upper'] = None
                forecasts[f'{metric}_lower'] = None
                forecasts[f'{metric}_trend'] = None

        return pd.DataFrame(forecasts)

    def load_models(self):
        """Load saved forecasters or train new ones"""
        try:
            if os.path.exists(FORECASTER_FILE):
                self.models = joblib.load(FORECASTER_FILE)
                print("Loaded existing forecast models")
            else:
                print("No saved forecast models found - training new ones")
                df = pd.read_csv(LABELED_DATA)
                self.train_forecasters(df)
        except Exception as e:
            print(f"Error loading forecast models: {e}")
            df = pd.read_csv(LABELED_DATA)
            self.train_forecasters(df)

"""Alert System"""

class KafkaMonitor:
    def __init__(self):
        self.classifier = KafkaCrashClassifier()
        self.forecaster = MetricForecaster()
        self.last_alert_time = None
        self.crash_prob_history = []
        self.metrics_history = []
        self.history_window = 360  # Keep last hour of data (at 5s intervals)

    def query_prometheus(self):
        def fetch_metric(query):
            try:
                response = requests.get(PROMETHEUS_URL+'/api/v1/query', params={'query': query})
                response.raise_for_status()
                result = response.json()
                if result['status'] == 'success' and result['data']['result']:
                    return float(result['data']['result'][0]['value'][1])
                else:
                    return None
            except Exception as e:
                print(f"Error querying Prometheus for {query}: {e}")
                return None

        metrics = {
            'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        }

        # Get Kafka metrics
        for key, query in KAFKA_METRICS.items():
            metrics[key] = fetch_metric(query)

        # Get Node Exporter metrics
        for key, query in NODE_METRICS.items():
            metrics[key] = fetch_metric(query)

        return metrics
    def calculate_crash_probability(self, current_metrics, forecast_data):
        """Predict crash probability using classifier with enhanced features"""
        if not self.classifier.model:
            print("No classifier model available")
            return 0.0

        try:
            # Add current metrics to history
            self.metrics_history.append(current_metrics)
            if len(self.metrics_history) > self.history_window:
                self.metrics_history.pop(0)

            # Create DataFrame from recent history
            hist_df = pd.DataFrame(self.metrics_history)
            hist_df['timestamp'] = pd.to_datetime(hist_df['timestamp'])

            # Create features combining current state and history
            features = create_features(hist_df, forecast_data)

            # Get most recent feature set
            if len(features) == 0:
                return 0.0

            latest_features = features.iloc[[-1]].copy()

            # Predict probability
            prob = self.classifier.model.predict_proba(latest_features)[0, 1]
            self.crash_prob_history.append(prob)

            # Smooth probability with moving average
            if len(self.crash_prob_history) > 12:  # 1 minute window
                smoothed_prob = np.mean(self.crash_prob_history[-12:])
            else:
                smoothed_prob = prob

            return smoothed_prob

        except Exception as e:
            print(f"Prediction error: {e}")
            return 0.0

    def send_alert(self, message, severity='medium'):
        """Enhanced alerting with more context"""
        if severity == 'critical':
            alert_header = "ðŸ”´ CRITICAL ALERT: Kafka Crash Imminent"
            alert_sound = "\x07"  # System bell
        elif severity == 'high':
            alert_header = "ðŸŸ  HIGH ALERT: Kafka Crash Likely"
            alert_sound = ""
        else:
            alert_header = "ðŸŸ¡ WARNING: Potential Kafka Issues"
            alert_sound = ""

        # Format message with more context
        formatted_msg = (
            f"{alert_sound}\n{alert_header}\n"
            f"Time: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n"
            f"{message}\n"
            f"Recommended Action: {'Restart Kafka and investigate root cause' if severity == 'critical' else 'Check system metrics and logs'}"
        )

        print(formatted_msg)
        self.last_alert_time = datetime.now()

        # Here you would add actual alerting (email, Slack, etc.)
        # Example: requests.post(SLACK_WEBHOOK, json={'text': formatted_msg})

    def check_system(self):
        """Enhanced monitoring function with state tracking"""
        try:
            # 1. Get current metrics
            current_metrics = self.query_prometheus()

            # 2. Generate forecasts
            forecast_data = self.forecaster.forecast()

            # 3. Calculate crash probability
            prob = self.calculate_crash_probability(current_metrics, forecast_data)

            # 4. Determine severity based on probability and trends
            severity = next(
                (level for level, thresh in SEVERITY_LEVELS.items() if prob >= thresh),
                'info'
            )

            # 5. Check for rapid probability increase
            prob_increase = 0
            if len(self.crash_prob_history) > 6:
                prob_increase = prob - np.mean(self.crash_prob_history[-6:-3])

            # If probability is increasing rapidly, increase severity
            if prob_increase > 0.2 and severity == 'info':
                severity = 'low'
            elif prob_increase > 0.3 and severity in ['low', 'medium']:
                severity = 'high' if severity == 'medium' else 'medium'

            # 6. Send alerts if needed
            if severity != 'info':
                alert_msg = (
                    f"Crash probability: {prob:.1%} (trend: {'â†‘' if prob_increase > 0 else 'â†“'}{abs(prob_increase):.1%})\n"
                    f"Current metrics:\n"
                    f"- Messages/s: {current_metrics['messages_in']:.0f} (normal: {NORMAL_RANGES['messages_in'][0]:.0f}-{NORMAL_RANGES['messages_in'][1]:.0f})\n"
                    f"- CPU: {current_metrics['cpu_usage']:.1f}% (threshold: 80%)\n"
                    f"- Memory: {current_metrics['memory_usage']:.1f}% (threshold: 95%)\n"
                    f"- Disk: {current_metrics['disk_usage']:.1f}% (threshold: 90%)"
                )

                # Add forecast info if available
                if forecast_data is not None:
                    alert_msg += "\n\nForecasted trends:\n"
                    for metric in ['messages_in', 'cpu_usage', 'memory_usage']:
                        if f'{metric}_forecast' in forecast_data.columns:
                            trend = forecast_data[f'{metric}_trend'].values[0]
                            alert_msg += (
                                f"- {metric}: {'â†‘' if trend > 0 else 'â†“'}"
                                f"{abs(trend):.2f}/step\n"
                            )

                self.send_alert(alert_msg, severity)

            # Periodic status update
            if self.last_alert_time is None or (
                datetime.now() - self.last_alert_time).seconds >= ALERT_INTERVAL:
                status = "NORMAL" if prob < 0.3 else "WARNING"
                print(f"\nðŸ“Š Status: {status} | Crash risk: {prob:.1%} | "
                      f"CPU: {current_metrics['cpu_usage']:.1f}% | "
                      f"Memory: {current_metrics['memory_usage']:.1f}%")

            return prob, current_metrics

        except Exception as e:
            print(f"Monitoring error: {e}")
            return 0.0, None

"""Main Function"""

if __name__ == "__main__":
    # Initialize
    print("Initializing Kafka Crash Prediction System...")
    monitor = KafkaMonitor()

    # Set up scheduler for periodic retraining
    scheduler = BackgroundScheduler()
    scheduler.add_job(
        monitor.classifier.train_model,
        'interval',
        seconds=MODEL_RETRAIN_INTERVAL,
        next_run_time=datetime.now() + timedelta(seconds=10)
    )
    scheduler.start()

    # Main monitoring loop
    try:
        print("Starting Kafka crash monitoring... Press Ctrl+C to stop")

        # For demo purposes - store some history
        probs = []
        timestamps = []

        while True:
            prob, metrics = monitor.check_system()

            # Store for visualization
            probs.append(prob)
            timestamps.append(datetime.now())

            # Keep only last 100 points
            if len(probs) > 100:
                probs.pop(0)
                timestamps.pop(0)

            # Periodically plot probability trend
            if len(probs) > 10 and len(probs) % 20 == 0:
                plt.figure(figsize=(10, 4))
                plt.plot(timestamps, probs, marker='o')
                plt.axhline(y=SEVERITY_LEVELS['low'], color='y', linestyle='--', label='Low threshold')
                plt.axhline(y=SEVERITY_LEVELS['medium'], color='orange', linestyle='--', label='Medium threshold')
                plt.axhline(y=SEVERITY_LEVELS['high'], color='r', linestyle='--', label='High threshold')
                plt.title('Crash Probability Over Time')
                plt.ylabel('Probability')
                plt.xlabel('Time')
                plt.legend()
                plt.grid()
                plt.tight_layout()
                plt.show()

            time.sleep(5)  # Check every 5 seconds

    except KeyboardInterrupt:
        scheduler.shutdown()
        print("Monitoring stopped")
    except Exception as e:
        scheduler.shutdown()
        print(f"Fatal error: {e}")