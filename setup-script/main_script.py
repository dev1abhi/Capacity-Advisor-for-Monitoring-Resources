# -*- coding: utf-8 -*-
"""main_script.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1YLxQsCUSaTe9E23NVjp826ZayvG3koGI
"""

import requests
import csv
import time
from datetime import datetime

JMX_URL = "http://public_ip_aws_ec2:7071/metrics" #replace the public ip address of your aws ec2 instance
NODE_URL = "http://public_ip_aws_ec2:9100/metrics" #replace the public ip address of your aws ec2 instance
CSV_FILE = "stressed_node_metrics.csv"

JMX_METRICS = {
    "bytes_in": "kafka_server_BrokerTopicMetrics_BytesInPerSec_total",
    "bytes_out": "kafka_server_BrokerTopicMetrics_BytesOutPerSec_total"
}

def parse_prometheus_text(text):
    metrics = {}
    for line in text.splitlines():
        if line.startswith("#") or line.strip() == "":
            continue
        parts = line.split()
        if len(parts) == 2:
            key, val = parts
            try:
                metrics[key] = float(val)
            except ValueError:
                continue
    return metrics

def get_jmx_metrics():
    res = requests.get(JMX_URL)
    metrics = parse_prometheus_text(res.text)
    return {k: metrics.get(v, 0.0) for k, v in JMX_METRICS.items()}

def get_cpu_times(metrics):
    cpu_times = {"idle": 0.0, "total": 0.0}
    for k, v in metrics.items():
        if k.startswith("node_cpu_seconds_total{") and "cpu=" in k:
            cpu_times["total"] += v
            if 'mode="idle"' in k:
                cpu_times["idle"] += v
    return cpu_times

def write_to_csv(timestamp, jmx_data, node_data):
    fieldnames = ["timestamp", "bytes_in", "bytes_out", "cpu_usage"]
    try:
        with open(CSV_FILE, "r"):
            file_exists = True
    except FileNotFoundError:
        file_exists = False

    with open(CSV_FILE, "a", newline="") as csvfile:
        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)
        if not file_exists:
            writer.writeheader()
        row = {
            "timestamp": timestamp,
            **jmx_data,
            **node_data
        }
        writer.writerow(row)

def main():
    prev_cpu = None
    while True:
        try:
            timestamp = datetime.now().strftime("%d-%m-%Y %H:%M:%S")

            # Fetch current metrics
            jmx_data = get_jmx_metrics()
            node_res = requests.get(NODE_URL)
            node_metrics = parse_prometheus_text(node_res.text)
            cpu_times = get_cpu_times(node_metrics)

            # Compute CPU usage from delta
            if prev_cpu:
                idle_delta = cpu_times["idle"] - prev_cpu["idle"]
                total_delta = cpu_times["total"] - prev_cpu["total"]
                if total_delta > 0:
                    cpu_usage = 100 * (1 - idle_delta / total_delta)
                else:
                    cpu_usage = 0.0
            else:
                cpu_usage = 0.0  # First iteration, can't compute

            prev_cpu = cpu_times

            node_data = {"cpu_usage": round(cpu_usage, 2)}
            write_to_csv(timestamp, jmx_data, node_data)
            print(f"[{timestamp}] Metrics recorded: bytes_in={jmx_data['bytes_in']}, bytes_out={jmx_data['bytes_out']}, cpu_usage={node_data['cpu_usage']}")
        except Exception as e:
            print(f"Error: {e}")
        time.sleep(4)